\bibitem{Behnel}
S. Behnel, R. Bradshaw, C. Citro, L. Dalcin, D. S. Seljebotn and K. Smith, {\em Cython: the best of both worlds}, CiSE (2011) 13(2), pp. 31-3.

\bibitem{Belsley}
D.A. Belsley, E. Kuh and R.E. Welsch, {\em  Regression diagnostics: Identifying Influential Data and Sources of Colinearity}, Wiley (1980), pp. 244-261.

\bibitem{breiman1984classification} L. Breiman, J. Friedman, C. J. Stone  and R. A. Olshen, {\em Classification and regression trees}, CRC press (1984).

\bibitem{breiman2001random} L. Breiman, {\em Random forests}, Machine learning 45(1)(2001), pp. 5--32.

\bibitem{cornillon} P.A. Cornillon, A. Guyader, F. Husson, N. Jegou, J. Josse, M Kloareg, E. Matzner-Lober,  and L. Rouvi{\`e}re, {\em R for Statistics}, CRC Press (2012).

\bibitem{genuer2010}
R. Genuer, J.M. Poggi, and C. Tuleau-Malot. {\em Variable selection using random forests.} Pattern Recognition Letters 31, no. 14 (2010), pp. 2225-2236.

\bibitem{genuer2017}
R. Genuer, J.-M. Poggi, C. Tuleau-Malot, N. Villa-Vialaneix, {\em Random Forests for Big Data}. Big Data Research, 9(2017), pp. 28-46.

\bibitem{LAR}
B. Efron, T. Hastie, I. Johnstone and R. Tibshirani, {\em Least angle regression},  Ann. Statist. 32,2 (2004), pp. 407--499.

\bibitem{fenske2011identifying} N. Fenske, T. Kneib and T. Hothorn, {\em Identifying risk factors for severe childhood malnutrition by boosting additive quantile regression},  Journal of the American Statistical Association, 106(494) (2011), pp.494--510.

 \bibitem{freund1999short} Y. Freund, R. Schapire and N. Abe, {\em A short introduction to boosting}, Journal-Japanese Society For Artificial Intelligence 14(5) (1999), pp.771--780.
 
\bibitem{gal2016} Y. Gal, and G. Zoubin, {\em Dropout as a Bayesian approximation: Representing model uncertainty in deep learning} In international conference on machine learning (2016), pp. 1050-1059.
 
 \bibitem{gey2006}
S. Gey and J.M. Poggi, {\em Boosting and instability for regression trees}. Computational
statistics \& data analysis, (2006) 50(2) pp 533–550.
\bibitem{HastieTibshiraniFriedman}
T. Hastie, R. Tibshirani and J. Friedman, 
{\em The Elements of Statistical Learning}, Springer Series in Statistics (2009).

\bibitem{kriegler2007boosting} B. Kriegler and R. Berk, {\em  Boosting the quantile distribution: A cost-sensitive statistical learning procedure},  Preprint  (2007).

\bibitem{kriegler2010small} \sameauthor, {\em Small area estimation of the homeless in Los Angeles: An application of cost-sensitive stochastic gradient boosting}, The Annals of Applied Statistics, 4(3)(2010), pp.1234--1255.
 
\bibitem{meinshausen2006quantile} N. Meinshausen, {\em Quantile regression forests},  Journal of Machine Learning Research, 7(2006), pp.~983--999.

\bibitem{reis2005} 
M.S. Reis, and P. M. Saraiva. {\em Integration of data uncertainty in linear regression and process optimization.} AIChE journal 51.11 (2005), pp. 3007-3019.

\bibitem{Warwick}
 W.J. Nash, T. L. Sellers, S. R. Talbot, A. J. Cawthorn and B. B. Ford {\em
The Population Biology of Abalone (\_Haliotis\_ species) in Tasmania. I. Blacklip Abalone (\_H. rubra\_) from the North Coast and Islands of Bass Strait}, 
Sea Fisheries Division, Technical Report No. 48 (ISSN 1034-3288) (1994).

\bibitem{Quinlan}
   R.  Quinlan,  {\em Combining Instance-Based and Model-Based Learning}, In Proceedings on the Tenth International Conference of Machine Learning (1993), pp. 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.

 \bibitem{Ridgeway2007} G. Ridgeway, {\em Generalized Boosted Models: A guide to the gbm package}, (2007).
 
\bibitem{Scikit-learn} G. Varoquaux, L. Buitinck, G. Louppe, O. Grisel, F. Pedregosa, and A. Mueller, {\em Scikit-learn: Machine Learning Without Learning the Machinery}, GetMobile: Mobile Comp. and Comm. 19, 1 (2015), pp. 29-33.

\bibitem{verikas2011} A. Verikas, A. Gelzinis, and M. Bacauskiene, {\em  Mining data with random forests : A
survey and results of new tests}. Pattern Recognition, 44(2)(2011), pp. 330–349.

\bibitem{zheng2012}
S. Zheng {\em QBoost: Predicting quantiles with boosting for regression and binary classification}. Expert Systems with Applications. (2012) Feb 1;39(2), pp. 1687-97.
